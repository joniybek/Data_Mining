{
 "metadata": {
  "name": "thesis_modeling-Copy0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "from pandas.stats.api import ols\nimport pandas as pd\nimport matplotlib.pyplot as plt\n#%matplotlib inline\nimport numpy as np\nimport matplotlib.font_manager\nfrom scipy import stats\nfrom sklearn.preprocessing import scale\nimport sklearn.preprocessing as prep\nfrom sklearn import svm\nfrom sklearn.decomposition import PCA\nfrom sklearn.cross_validation import cross_val_score",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Read file\ndf=pd.read_csv('df3.csv')",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 217
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# Select features to feed tha algorithm\nlistOfFeatures2=['NumStud_total','1 Q','2 Q','3 Q','4 Q','5 Q','6  Q','7 Q','8 Q','9 Q','10 Q','11 Q']\nfeature_x=np.array(df[listOfFeatures2],dtype=\"float64\")\n#target_y=np.array(df[['numDecision']],dtype=\"float64\")\ntarget_y=df['numDecision'].values",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 745
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# Scale features\nfeature_x=prep.scale(feature_x)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 713
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# Random forest and ExtraTreesClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier #ExtraTreesClassifier\nfrom sklearn.feature_extraction import DictVectorizer\nforest = ExtraTreesClassifier(criterion='gini',n_estimators=250,random_state=1)\n# Feed and evaluate with CV\n%%time\nscores=cross_val_score(forest,feature_x,target_y,cv=10)\nscores.mean()",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 667
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# SVM classifier\n%%time\nsvm1 = svm.SVC(C=1,kernel='rbf',gamma=0.0,probability=False)\nscores=cross_val_score(svm1,feature_x,target_y,cv=10)\nscores.mean()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "Wall time: 500 ms\n"
      }
     ],
     "prompt_number": 644
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# Decision tree classifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree\n%%time\nscores=cross_val_score(dt,feature_x,target_y,cv=10)\nscores.mean()",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 545
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# Export graph of DT\ntree.export_graphviz(dt,out_file='tree.dot',feature_names=listOfFeatures2)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 498
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# This is for getting confusion matrix, firstly feed with train and test, reolace classifier with forest,svm1 or tree\nfrom sklearn.metrics import confusion_matrix\nX_train1, X_test1, y_train1, y_test1 = train_test_split(feature_x, target_y, test_size=0.5, random_state=0)\nclassifier.fit(X_train1,y_train1)\ny_pred=classifier.predict(X_test1)\nconfusion_matrix(y_test1, y_pred)",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "%%time\nfrom sklearn.cross_validation import train_test_split\nfrom scipy.stats import randint as sp_randint\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn.metrics import classification_report\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nX_train, X_test, y_train, y_test = train_test_split(feature_x, target_y, test_size=0.2, random_state=0)\n\n# Set the parameters by cross-validation\n#tuned_parameters = [{'kernel': ['rbf'], 'gamma': [0,1e-1,1e-2,1e-3],'C': [1, 10, 100]},\n#                    {'kernel': ['linear'], 'C': [1, 10, 100]}]\n\n\n#tuned_parameters = {'n_estimators':[250],\"max_depth\": [3, None], \"max_features\": [1, 3, 10], \"min_samples_split\": [1, 3, 10],\n#              \"min_samples_leaf\": [1, 3, 10],  \"bootstrap\": [True, False], \"criterion\": [\"gini\", \"entropy\"]}\n\n\n#tuned_parameters = {\"max_depth\": [3, None],\"max_features\": [1, 3, 10], \"min_samples_split\": [1, 3, 10],\n#              \"min_samples_leaf\": [1, 3, 10], \"criterion\": [\"gini\", \"entropy\"]}\n\ntuned_parameters = {'n_estimators':[250],\"max_depth\": [3], \"max_features\": [10], \"min_samples_split\": [1, 3, 10],\n              \"min_samples_leaf\": [ 3],  \"bootstrap\": [True], \"criterion\": [ \"entropy\"]}\n\n\n\nclassifierList=list()\n\n\n\nscores = ['precision', 'recall','f1']\n\nfor score in scores:\n    print(\"# Tuning hyper-parameters for %s\" % score)\n    print\n\n    clf = GridSearchCV(RandomForestClassifier(n_jobs=3), tuned_parameters, cv=5,\n                       scoring='%s' % score)\n    clf.fit(X_train, y_train)\n\n    print(\"Best parameters set found on development set:\")\n    print\n    print(clf.best_params_)\n    print\n    print(\"Grid scores on development set:\")\n    print\n    #for params, mean_score, scores in clf.grid_scores_:\n    #    print(\"%0.3f (+/-%0.03f)  %r\"\n    #          % (mean_score, scores.std() * 2, params))\n    print\n\n    print(\"Detailed classification report:\")\n    print\n    print(\"The model is trained on the full development set.\")\n    print(\"The scores are computed on the full evaluation set.\")\n    print\n    y_true, y_pred = y_test, clf.predict(X_test)\n    print(classification_report(y_true, y_pred))\n    classifierList.append(clf.best_estimator_)\n    print\n",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "# Tuning hyper-parameters for precision\n\nBest parameters set found on development set:"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\n\n{'bootstrap': True, 'min_samples_leaf': 3, 'n_estimators': 250, 'min_samples_split': 10, 'criterion': 'entropy', 'max_features': 10, 'max_depth': 3}\n\nGrid scores on development set:\n\n\nDetailed classification report:\n\nThe model is trained on the full development set.\nThe scores are computed on the full evaluation set.\n\n             precision    recall  f1-score   support\n\n          0       0.94      1.00      0.97        51\n          1       0.83      0.71      0.77         7\n          2       0.50      0.25      0.33         8\n          3       0.56      0.71      0.63         7\n\navg / total       0.85      0.86      0.85        73\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\n\n# Tuning hyper-parameters for recall\n\nBest parameters set found on development set:"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\n\n{'bootstrap': True, 'min_samples_leaf': 3, 'n_estimators': 250, 'min_samples_split': 1, 'criterion': 'entropy', 'max_features': 10, 'max_depth': 3}\n\nGrid scores on development set:\n\n\nDetailed classification report:\n\nThe model is trained on the full development set.\nThe scores are computed on the full evaluation set.\n\n             precision    recall  f1-score   support\n\n          0       0.94      1.00      0.97        51\n          1       0.80      0.57      0.67         7\n          2       0.25      0.12      0.17         8\n          3       0.50      0.71      0.59         7\n\navg / total       0.81      0.84      0.82        73\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\n\n# Tuning hyper-parameters for f1\n\nBest parameters set found on development set:"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\n\n{'bootstrap': True, 'min_samples_leaf': 3, 'n_estimators': 250, 'min_samples_split': 3, 'criterion': 'entropy', 'max_features': 10, 'max_depth': 3}\n\nGrid scores on development set:\n\n\nDetailed classification report:\n\nThe model is trained on the full development set.\nThe scores are computed on the full evaluation set.\n\n             precision    recall  f1-score   support\n\n          0       0.94      1.00      0.97        51\n          1       0.83      0.71      0.77         7\n          2       0.33      0.12      0.18         8\n          3       0.50      0.71      0.59         7\n\navg / total       0.82      0.85      0.83        73\n"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\n\nWall time: 57.2 s\n"
      }
     ],
     "prompt_number": 746
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "%%time\n#this is rechecking avarage score with cross-valid\nscores=cross_val_score(classifierList[0],feature_x,target_y,cv=10)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "Wall time: 14.7 s\n"
      }
     ],
     "prompt_number": 747
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "scores.mean()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 748,
       "text": "0.86806001490212026"
      }
     ],
     "prompt_number": 748
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# this is for exporting dot file\ntree.export_graphviz(classifierList[0],out_file='tree.dot',feature_names=listOfFeatures2)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 711
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "classifierList[0]",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 721,
       "text": "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0,\n  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n  shrinking=True, tol=0.001, verbose=False)"
      }
     ],
     "prompt_number": 721
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "feature_x",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 731,
       "text": "array([[ 29.  ,   4.64,   4.45, ...,   4.4 ,   4.56,   4.44],\n       [ 14.  ,   4.89,   4.89, ...,   4.38,   4.78,   5.  ],\n       [ 16.  ,   4.22,   3.67, ...,   4.63,   4.33,   4.78],\n       ..., \n       [ 29.  ,   4.65,   4.04, ...,   4.05,   4.09,   3.91],\n       [  7.  ,   4.67,   3.83, ...,   4.67,   4.17,   4.5 ],\n       [ 12.  ,   4.17,   4.33, ...,   4.4 ,   3.83,   4.17]])"
      }
     ],
     "prompt_number": 731
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 735,
       "text": "array([[125,   0,   0,   0],\n       [  1,  10,   3,   4],\n       [  1,   4,   3,  10],\n       [  2,   0,   1,  18]])"
      }
     ],
     "prompt_number": 735
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#this is for plotting feature importance\nclassifierList[1].fit(feature_x,target_y)\npd.DataFrame(classifierList[1].feature_importances_,index=listOfFeatures2 ).plot(kind='bar')\nplt.show()",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 737
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#this is part with teachers",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "listOfFeatures=['Teacher','numDecision','NumStud_total','NumStud_filled','1 Q','2 Q','3 Q','4 Q','5 Q','6  Q','7 Q','8 Q','9 Q','10 Q','11 Q']\ndf2=df[df['numDecision']>1][listOfFeatures].T.to_dict().values()",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 354
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "vec = DictVectorizer(sparse = False)\nnpv=vec.fit_transform(df2)\ndfb=pd.DataFrame(npv,columns=vec.get_feature_names())\ndfb['otherTeacher']=0",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 355
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "listOfFeatures=['Teacher','numDecision','NumStud_total','NumStud_filled','1 Q','2 Q','3 Q','4 Q','5 Q','6  Q','7 Q','8 Q','9 Q','10 Q','11 Q']\ndfw=df[df['numDecision']<=1][listOfFeatures]",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 356
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#del dfw['Teacher']\ndfw['otherTeacher']=1\n#notListOfFeatures=[x for x in vec.get_feature_names() if x not in listOfFeatures ]\n#dfw[[ [x] for x in notListOfFeatures]]=0\n#dfw.head().T\ndf3=pd.concat([dfb,dfw], axis=0)\ndf3=df3.fillna(0)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 363
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "svm1 = svm.SVC(kernel='rbf')\nfeature_x2=np.array(df3[[x for x in df3.columns if x!='numDecision']],dtype=\"float64\")\n#target_y=np.array(df[['numDecision']],dtype=\"float64\")\ntarget_y2=df['numDecision'].values",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 370
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "%%time\nscores=cross_val_score(svm1,feature_x2,target_y2,cv=10)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "Wall time: 594 ms\n"
      }
     ],
     "prompt_number": 371
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "scores.mean()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 372,
       "text": "0.68966594413962834"
      }
     ],
     "prompt_number": 372
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}